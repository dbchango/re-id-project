{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## TF tunner samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from processing import load_image_dataset\n",
    "\n",
    "x_lbp_train, y_lbp_train = load_image_dataset('Datasets/espe/lbp_histograms - copia/train', (40, 40), True)\n",
    "x_lbp_test, y_lbp_test = load_image_dataset('Datasets/espe/lbp_histograms - copia/test', (40, 40), True)\n",
    "x_lbp_validation, y_lbp_validation = load_image_dataset('Datasets/espe/lbp_histograms - copia/validation', (40, 40), True)\n",
    "\n",
    "x_masks_train, y_masks_train = load_image_dataset('Datasets/espe/masks/train', (40, 40), True)\n",
    "x_masks_test, y_masks_test = load_image_dataset('Datasets/espe/masks/test', (40, 40), True)\n",
    "x_masks_validation, y_masks_validation = load_image_dataset('Datasets/espe/masks/validation', (40, 40), True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train rgb shape: (10507, 40, 40, 1) \t x train masks shape: (10507, 40, 40, 1) \t same?: True\n",
      "x test rgb shape: (2261, 40, 40, 1) \t x test masks shape: (2261, 40, 40, 1)  \t same?: True\n",
      "x validation rgb shape: (2527, 40, 40, 1) \t x validation masks shape: (2527, 40, 40, 1) \t same?: True\n"
     ]
    }
   ],
   "source": [
    "print(\"x train rgb shape: {} \\t x train masks shape: {} \\t same?: {}\".format(x_lbp_train.shape, x_masks_train.shape, x_lbp_train.shape==x_masks_train.shape ))\n",
    "print(\"x test rgb shape: {} \\t x test masks shape: {}  \\t same?: {}\".format(x_lbp_test.shape, x_masks_test.shape, x_lbp_test.shape==x_masks_test.shape))\n",
    "print(\"x validation rgb shape: {} \\t x validation masks shape: {} \\t same?: {}\".format(x_lbp_validation.shape, x_masks_validation.shape, x_lbp_validation.shape==x_masks_validation.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_masks_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_masks, y_masks = np.concatenate((x_masks_train/255, x_masks_validation/255), axis=0), np.concatenate((y_masks_train, y_masks_validation), axis=0)\n",
    "# concatenation with normalization\n",
    "x_lbp, y_lbp = np.concatenate((x_lbp_train/255, x_lbp_validation/255), axis=0), np.concatenate((y_lbp_train, y_lbp_validation), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((13034, 40, 40, 1), (13034, 40, 40, 1))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_masks.shape, x_lbp.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# First work models training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training LBP identification model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 2s 245us/sample - loss: 1.9473 - acc: 0.1470 - val_loss: 1.9457 - val_acc: 0.1456\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 1.9165 - acc: 0.2041 - val_loss: 1.8750 - val_acc: 0.2417\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 1.7281 - acc: 0.3316 - val_loss: 1.7991 - val_acc: 0.2986\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 1.4619 - acc: 0.4500 - val_loss: 1.4915 - val_acc: 0.4379\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 1.1334 - acc: 0.5909 - val_loss: 1.4909 - val_acc: 0.4517\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.9372 - acc: 0.6718 - val_loss: 1.3040 - val_acc: 0.5270\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.7742 - acc: 0.7374 - val_loss: 1.5133 - val_acc: 0.4862\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.6842 - acc: 0.7626 - val_loss: 1.5306 - val_acc: 0.5144\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.6353 - acc: 0.7895 - val_loss: 1.4253 - val_acc: 0.5414\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.5925 - acc: 0.8113 - val_loss: 1.2383 - val_acc: 0.5944\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.4672 - acc: 0.8412 - val_loss: 1.3112 - val_acc: 0.5673\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.4705 - acc: 0.8387 - val_loss: 1.4801 - val_acc: 0.5604\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.3780 - acc: 0.8717 - val_loss: 1.3705 - val_acc: 0.5909\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.3277 - acc: 0.8892 - val_loss: 1.4704 - val_acc: 0.5967\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.4328 - acc: 0.8567 - val_loss: 1.3436 - val_acc: 0.6145\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.2621 - acc: 0.9091 - val_loss: 2.1245 - val_acc: 0.5138\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.2710 - acc: 0.9115 - val_loss: 1.4309 - val_acc: 0.6070\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.2907 - acc: 0.9127 - val_loss: 1.3129 - val_acc: 0.6542\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 1s 129us/sample - loss: 0.1719 - acc: 0.9439 - val_loss: 1.6637 - val_acc: 0.5863\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.2085 - acc: 0.9366 - val_loss: 2.0422 - val_acc: 0.5685\n",
      "4345/4345 [==============================] - 1s 148us/sample - loss: 0.8425 - acc: 0.7708\n",
      "Score for fold 1: loss of 0.8424717795330993; acc of 77.07710266113281%\n",
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 1s 129us/sample - loss: 0.2912 - acc: 0.9013 - val_loss: 1.2773 - val_acc: 0.6473\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.3057 - acc: 0.9020 - val_loss: 1.2121 - val_acc: 0.6536\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.1638 - acc: 0.9472 - val_loss: 1.6323 - val_acc: 0.5967\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 1s 130us/sample - loss: 0.1403 - acc: 0.9522 - val_loss: 1.4231 - val_acc: 0.6761\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.1963 - acc: 0.9468 - val_loss: 1.4455 - val_acc: 0.6830\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.1286 - acc: 0.9553 - val_loss: 1.7163 - val_acc: 0.6450\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.1266 - acc: 0.9682 - val_loss: 2.3238 - val_acc: 0.5564\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.0696 - acc: 0.9827 - val_loss: 1.9697 - val_acc: 0.6312\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.0728 - acc: 0.9778 - val_loss: 1.6431 - val_acc: 0.6899\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.3365 - acc: 0.9376 - val_loss: 1.5708 - val_acc: 0.6858\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.0135 - acc: 0.9984 - val_loss: 1.7678 - val_acc: 0.6847\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.2506 - acc: 0.9468 - val_loss: 1.5143 - val_acc: 0.6997\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.0076 - acc: 0.9997 - val_loss: 1.8112 - val_acc: 0.6743\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.1749 - acc: 0.9581 - val_loss: 1.6980 - val_acc: 0.6985\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.0051 - acc: 0.9997 - val_loss: 1.8215 - val_acc: 0.7054\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.4597 - acc: 0.9419 - val_loss: 1.6656 - val_acc: 0.6870\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.0088 - acc: 0.9993 - val_loss: 1.7596 - val_acc: 0.6974\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 1s 128us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 2.0082 - val_acc: 0.6985\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 1s 128us/sample - loss: 0.2044 - acc: 0.9613 - val_loss: 1.8774 - val_acc: 0.6910\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.0049 - acc: 0.9996 - val_loss: 1.8410 - val_acc: 0.7083\n",
      "4345/4345 [==============================] - 1s 155us/sample - loss: 0.4931 - acc: 0.9125\n",
      "Score for fold 2: loss of 0.4930768026796901; acc of 91.25431776046753%\n",
      "Train on 6952 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6952/6952 [==============================] - 1s 126us/sample - loss: 0.2026 - acc: 0.9482 - val_loss: 1.7026 - val_acc: 0.6784\n",
      "Epoch 2/20\n",
      "6952/6952 [==============================] - 1s 127us/sample - loss: 0.0895 - acc: 0.9771 - val_loss: 2.0742 - val_acc: 0.6513\n",
      "Epoch 3/20\n",
      "6952/6952 [==============================] - 1s 125us/sample - loss: 0.0257 - acc: 0.9931 - val_loss: 1.8102 - val_acc: 0.6726\n",
      "Epoch 4/20\n",
      "6952/6952 [==============================] - 1s 127us/sample - loss: 0.2076 - acc: 0.9541 - val_loss: 1.5922 - val_acc: 0.6922\n",
      "Epoch 5/20\n",
      "6952/6952 [==============================] - 1s 126us/sample - loss: 0.1020 - acc: 0.9748 - val_loss: 1.4534 - val_acc: 0.6916\n",
      "Epoch 6/20\n",
      "6952/6952 [==============================] - 1s 125us/sample - loss: 0.0118 - acc: 0.9976 - val_loss: 1.8484 - val_acc: 0.6870\n",
      "Epoch 7/20\n",
      "6952/6952 [==============================] - 1s 129us/sample - loss: 0.2502 - acc: 0.9439 - val_loss: 1.6472 - val_acc: 0.6818\n",
      "Epoch 8/20\n",
      "6952/6952 [==============================] - 1s 126us/sample - loss: 0.0082 - acc: 0.9996 - val_loss: 1.7124 - val_acc: 0.6979\n",
      "Epoch 9/20\n",
      "6952/6952 [==============================] - 1s 125us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 2.0358 - val_acc: 0.6939\n",
      "Epoch 10/20\n",
      "6952/6952 [==============================] - 1s 127us/sample - loss: 0.3045 - acc: 0.9543 - val_loss: 2.0681 - val_acc: 0.6594\n",
      "Epoch 11/20\n",
      "6952/6952 [==============================] - 1s 126us/sample - loss: 0.0034 - acc: 0.9997 - val_loss: 2.1437 - val_acc: 0.6738\n",
      "Epoch 12/20\n",
      "6952/6952 [==============================] - 1s 125us/sample - loss: 0.1809 - acc: 0.9763 - val_loss: 2.1885 - val_acc: 0.6174\n",
      "Epoch 13/20\n",
      "6952/6952 [==============================] - 1s 127us/sample - loss: 0.0104 - acc: 0.9976 - val_loss: 2.1369 - val_acc: 0.6784\n",
      "Epoch 14/20\n",
      "6952/6952 [==============================] - 1s 127us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1596 - val_acc: 0.6939\n",
      "Epoch 15/20\n",
      "6952/6952 [==============================] - 1s 129us/sample - loss: 0.1858 - acc: 0.9829 - val_loss: 3.6285 - val_acc: 0.5650\n",
      "Epoch 16/20\n",
      "6952/6952 [==============================] - 1s 127us/sample - loss: 0.0703 - acc: 0.9850 - val_loss: 2.2026 - val_acc: 0.6669\n",
      "Epoch 17/20\n",
      "6952/6952 [==============================] - 1s 126us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 2.2701 - val_acc: 0.6835\n",
      "Epoch 18/20\n",
      "6952/6952 [==============================] - 1s 126us/sample - loss: 3.7376e-04 - acc: 1.0000 - val_loss: 2.7051 - val_acc: 0.6605\n",
      "Epoch 19/20\n",
      "6952/6952 [==============================] - 1s 125us/sample - loss: 0.1409 - acc: 0.9760 - val_loss: 2.2247 - val_acc: 0.6904\n",
      "Epoch 20/20\n",
      "6952/6952 [==============================] - 1s 126us/sample - loss: 5.0666e-04 - acc: 1.0000 - val_loss: 2.3377 - val_acc: 0.6864\n",
      "4344/4344 [==============================] - 1s 149us/sample - loss: 0.4511 - acc: 0.9395\n",
      "Score for fold 3: loss of 0.45113828601375044; acc of 93.94567012786865%\n",
      "Wall time: 59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models import *\n",
    "from training.utils import cv_training\n",
    "\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "model = None\n",
    "model = individual_feature_model((40, 40, 1), y_masks_train.shape[1])\n",
    "\n",
    "cv_training(model=model, n_splits=3, x_data=[x_lbp], y_data=y_lbp, path_to_save_results='models/texture-silhouette/own/textures', batch_size=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "2261/2261 [==============================] - 1s 281us/sample - loss: 1.6914 - acc: 0.6249\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.6914048448488386, 0.6249447]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "model = load_model('models/own/experiments/lbp_model/experiment_1/model_3.h5')\n",
    "model.evaluate(x_lbp_test/255, y_lbp_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training masks identification model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 1s 208us/sample - loss: 1.7968 - acc: 0.2695 - val_loss: 2.0247 - val_acc: 0.2532\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 1s 141us/sample - loss: 1.1146 - acc: 0.5975 - val_loss: 2.2591 - val_acc: 0.3015\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 1s 141us/sample - loss: 0.6887 - acc: 0.7603 - val_loss: 2.0618 - val_acc: 0.3596\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 1s 137us/sample - loss: 0.4725 - acc: 0.8350 - val_loss: 2.3608 - val_acc: 0.4010\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 1s 140us/sample - loss: 0.3454 - acc: 0.8812 - val_loss: 2.6488 - val_acc: 0.4246\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 1s 141us/sample - loss: 0.2492 - acc: 0.9128 - val_loss: 2.5566 - val_acc: 0.4143\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 1s 140us/sample - loss: 0.1757 - acc: 0.9417 - val_loss: 3.1121 - val_acc: 0.4160\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.1412 - acc: 0.9535 - val_loss: 3.0235 - val_acc: 0.4471\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.1200 - acc: 0.9573 - val_loss: 3.3533 - val_acc: 0.4246\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 1s 137us/sample - loss: 0.0979 - acc: 0.9658 - val_loss: 3.5151 - val_acc: 0.4591\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.0660 - acc: 0.9784 - val_loss: 3.5892 - val_acc: 0.4603\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.0764 - acc: 0.9742 - val_loss: 3.6701 - val_acc: 0.4407\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 1s 138us/sample - loss: 0.0470 - acc: 0.9832 - val_loss: 4.0936 - val_acc: 0.4315\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 1s 138us/sample - loss: 0.0468 - acc: 0.9845 - val_loss: 3.9828 - val_acc: 0.4482\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 1s 142us/sample - loss: 0.0729 - acc: 0.9776 - val_loss: 4.4757 - val_acc: 0.4091\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.0650 - acc: 0.9786 - val_loss: 3.9739 - val_acc: 0.4534\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.0803 - acc: 0.9747 - val_loss: 3.8424 - val_acc: 0.4545\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 1s 141us/sample - loss: 0.0303 - acc: 0.9921 - val_loss: 4.2072 - val_acc: 0.4534\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 1s 138us/sample - loss: 0.0121 - acc: 0.9964 - val_loss: 4.7391 - val_acc: 0.4505\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.0210 - acc: 0.9931 - val_loss: 5.1752 - val_acc: 0.4367\n",
      "4345/4345 [==============================] - 1s 148us/sample - loss: 1.5301 - acc: 0.7830\n",
      "Score for fold 1: loss of 1.5300902216289067; acc of 78.29689383506775%\n",
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 1s 141us/sample - loss: 0.3046 - acc: 0.9104 - val_loss: 2.2532 - val_acc: 0.4649\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.1283 - acc: 0.9570 - val_loss: 3.0236 - val_acc: 0.4666\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 1s 136us/sample - loss: 0.0745 - acc: 0.9751 - val_loss: 2.7632 - val_acc: 0.4902\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.0569 - acc: 0.9817 - val_loss: 3.3917 - val_acc: 0.4672\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 1s 143us/sample - loss: 0.0513 - acc: 0.9817 - val_loss: 3.5532 - val_acc: 0.4891\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 1s 142us/sample - loss: 0.0277 - acc: 0.9894 - val_loss: 3.9056 - val_acc: 0.4839\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 1s 138us/sample - loss: 0.0308 - acc: 0.9909 - val_loss: 3.5497 - val_acc: 0.4850\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 1s 142us/sample - loss: 0.0209 - acc: 0.9932 - val_loss: 4.0635 - val_acc: 0.4873\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 1s 140us/sample - loss: 0.0197 - acc: 0.9941 - val_loss: 4.2051 - val_acc: 0.4960\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.0102 - acc: 0.9967 - val_loss: 4.7496 - val_acc: 0.4730\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 1s 138us/sample - loss: 0.0250 - acc: 0.9919 - val_loss: 3.9978 - val_acc: 0.4931\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 1s 141us/sample - loss: 0.0286 - acc: 0.9906 - val_loss: 4.3801 - val_acc: 0.4868\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 1s 138us/sample - loss: 0.0336 - acc: 0.9888 - val_loss: 4.3936 - val_acc: 0.4758\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 1s 142us/sample - loss: 0.0277 - acc: 0.9915 - val_loss: 4.4878 - val_acc: 0.4747\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 1s 142us/sample - loss: 0.0142 - acc: 0.9953 - val_loss: 4.1087 - val_acc: 0.4816\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.0119 - acc: 0.9968 - val_loss: 4.7106 - val_acc: 0.4787\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 1s 138us/sample - loss: 0.0188 - acc: 0.9948 - val_loss: 5.1397 - val_acc: 0.4649\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 1s 139us/sample - loss: 0.0162 - acc: 0.9934 - val_loss: 4.3824 - val_acc: 0.4816\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 1s 141us/sample - loss: 0.0136 - acc: 0.9948 - val_loss: 5.0779 - val_acc: 0.4799\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 1s 141us/sample - loss: 0.0158 - acc: 0.9957 - val_loss: 4.7232 - val_acc: 0.4776\n",
      "4345/4345 [==============================] - 1s 159us/sample - loss: 1.0783 - acc: 0.8628\n",
      "Score for fold 2: loss of 1.0783414802020082; acc of 86.28308176994324%\n",
      "Train on 6952 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6952/6952 [==============================] - 1s 142us/sample - loss: 0.1156 - acc: 0.9653 - val_loss: 3.7964 - val_acc: 0.4356\n",
      "Epoch 2/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0586 - acc: 0.9800 - val_loss: 4.3412 - val_acc: 0.4505\n",
      "Epoch 3/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0186 - acc: 0.9938 - val_loss: 4.0346 - val_acc: 0.4845\n",
      "Epoch 4/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0138 - acc: 0.9960 - val_loss: 4.4087 - val_acc: 0.4787\n",
      "Epoch 5/20\n",
      "6952/6952 [==============================] - 1s 140us/sample - loss: 0.0130 - acc: 0.9958 - val_loss: 4.5540 - val_acc: 0.4689\n",
      "Epoch 6/20\n",
      "6952/6952 [==============================] - 1s 142us/sample - loss: 0.0172 - acc: 0.9941 - val_loss: 4.8255 - val_acc: 0.4505\n",
      "Epoch 7/20\n",
      "6952/6952 [==============================] - 1s 144us/sample - loss: 0.0132 - acc: 0.9955 - val_loss: 5.6809 - val_acc: 0.4574\n",
      "Epoch 8/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0245 - acc: 0.9914 - val_loss: 5.1668 - val_acc: 0.4522\n",
      "Epoch 9/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0409 - acc: 0.9879 - val_loss: 4.5947 - val_acc: 0.4649\n",
      "Epoch 10/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0291 - acc: 0.9909 - val_loss: 4.1378 - val_acc: 0.5046\n",
      "Epoch 11/20\n",
      "6952/6952 [==============================] - 1s 139us/sample - loss: 0.0115 - acc: 0.9964 - val_loss: 4.5431 - val_acc: 0.4954\n",
      "Epoch 12/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0114 - acc: 0.9955 - val_loss: 4.7249 - val_acc: 0.4787\n",
      "Epoch 13/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0053 - acc: 0.9978 - val_loss: 4.8279 - val_acc: 0.4942\n",
      "Epoch 14/20\n",
      "6952/6952 [==============================] - 1s 140us/sample - loss: 0.0032 - acc: 0.9988 - val_loss: 4.7396 - val_acc: 0.4988\n",
      "Epoch 15/20\n",
      "6952/6952 [==============================] - 1s 139us/sample - loss: 0.0032 - acc: 0.9987 - val_loss: 5.4123 - val_acc: 0.4885\n",
      "Epoch 16/20\n",
      "6952/6952 [==============================] - 1s 140us/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 5.0005 - val_acc: 0.4914\n",
      "Epoch 17/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0062 - acc: 0.9986 - val_loss: 5.3185 - val_acc: 0.4891\n",
      "Epoch 18/20\n",
      "6952/6952 [==============================] - 1s 139us/sample - loss: 0.0036 - acc: 0.9988 - val_loss: 5.7619 - val_acc: 0.4764\n",
      "Epoch 19/20\n",
      "6952/6952 [==============================] - 1s 142us/sample - loss: 0.0140 - acc: 0.9964 - val_loss: 4.9897 - val_acc: 0.4747\n",
      "Epoch 20/20\n",
      "6952/6952 [==============================] - 1s 142us/sample - loss: 0.0304 - acc: 0.9909 - val_loss: 4.4150 - val_acc: 0.4563\n",
      "4344/4344 [==============================] - 1s 150us/sample - loss: 0.9430 - acc: 0.8688\n",
      "Score for fold 3: loss of 0.9429998395142238; acc of 86.87845468521118%\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models import *\n",
    "from training.utils import cv_training\n",
    "\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "input_shape = x_masks.shape[1:]\n",
    "model = None\n",
    "model = individual_feature_model(input_shape, y_masks_train.shape[1])\n",
    "\n",
    "cv_training(model=model, n_splits=3, x_data=[x_masks], y_data=y_masks, path_to_save_results='models/texture-silhouette_2/silhouette')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluating model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "model = load_model('models/own/experiments/sillhouette_model/experiment_2/model_3.h5')\n",
    "model.evaluate(x_masks_test, y_masks_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training double input images with siamese model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 3s 472us/sample - loss: 1.9331 - acc: 0.1849 - val_loss: 1.9446 - val_acc: 0.1387\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 2s 318us/sample - loss: 1.8601 - acc: 0.3584 - val_loss: 1.9205 - val_acc: 0.2152\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 2s 325us/sample - loss: 1.7685 - acc: 0.4735 - val_loss: 1.8801 - val_acc: 0.2618\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 2s 318us/sample - loss: 1.6481 - acc: 0.6025 - val_loss: 1.8116 - val_acc: 0.3838\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 2s 317us/sample - loss: 1.5070 - acc: 0.7039 - val_loss: 1.7530 - val_acc: 0.4591\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 2s 319us/sample - loss: 1.3748 - acc: 0.7409 - val_loss: 1.7138 - val_acc: 0.4528\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 2s 321us/sample - loss: 1.2475 - acc: 0.7730 - val_loss: 1.6124 - val_acc: 0.5155\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 2s 322us/sample - loss: 1.1282 - acc: 0.7851 - val_loss: 1.6564 - val_acc: 0.4448\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 2s 324us/sample - loss: 1.0218 - acc: 0.8069 - val_loss: 1.5656 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 2s 331us/sample - loss: 0.9169 - acc: 0.8216 - val_loss: 1.4600 - val_acc: 0.5472\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 2s 318us/sample - loss: 0.8167 - acc: 0.8400 - val_loss: 1.5280 - val_acc: 0.5414\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 2s 319us/sample - loss: 0.7377 - acc: 0.8498 - val_loss: 1.4660 - val_acc: 0.5696\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 2s 317us/sample - loss: 0.6561 - acc: 0.9015 - val_loss: 1.4126 - val_acc: 0.5742\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 2s 320us/sample - loss: 0.5873 - acc: 0.9202 - val_loss: 1.3620 - val_acc: 0.6093\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 2s 316us/sample - loss: 0.5156 - acc: 0.9455 - val_loss: 1.5342 - val_acc: 0.5518\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 2s 317us/sample - loss: 0.4557 - acc: 0.9551 - val_loss: 1.3469 - val_acc: 0.6116\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 2s 314us/sample - loss: 0.4038 - acc: 0.9557 - val_loss: 1.4025 - val_acc: 0.6024\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 2s 315us/sample - loss: 0.3482 - acc: 0.9649 - val_loss: 1.4810 - val_acc: 0.5823\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 2s 313us/sample - loss: 0.3038 - acc: 0.9675 - val_loss: 1.4625 - val_acc: 0.6087\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 2s 313us/sample - loss: 0.2762 - acc: 0.9672 - val_loss: 1.5126 - val_acc: 0.5938\n",
      "4345/4345 [==============================] - 1s 183us/sample - loss: 0.5996 - acc: 0.8621\n",
      "Score for fold 1: loss of 0.5996359872049786; acc of 86.2140417098999%\n",
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 2s 315us/sample - loss: 0.3241 - acc: 0.9465 - val_loss: 1.5008 - val_acc: 0.6145\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 2s 317us/sample - loss: 0.2894 - acc: 0.9527 - val_loss: 1.4007 - val_acc: 0.6369\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 2s 316us/sample - loss: 0.2468 - acc: 0.9599 - val_loss: 1.4353 - val_acc: 0.6237\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 2s 311us/sample - loss: 0.2213 - acc: 0.9635 - val_loss: 1.5282 - val_acc: 0.6300\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 2s 317us/sample - loss: 0.2121 - acc: 0.9630 - val_loss: 1.6809 - val_acc: 0.5984\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 2s 315us/sample - loss: 0.1808 - acc: 0.9705 - val_loss: 1.4969 - val_acc: 0.6438\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 2s 317us/sample - loss: 0.1649 - acc: 0.9725 - val_loss: 1.5099 - val_acc: 0.6536\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 2s 313us/sample - loss: 0.1578 - acc: 0.9740 - val_loss: 1.5003 - val_acc: 0.6502\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 2s 316us/sample - loss: 0.1488 - acc: 0.9748 - val_loss: 1.7080 - val_acc: 0.6237\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 2s 322us/sample - loss: 0.1312 - acc: 0.9793 - val_loss: 1.8051 - val_acc: 0.6024\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 2s 320us/sample - loss: 0.1410 - acc: 0.9763 - val_loss: 1.5911 - val_acc: 0.6634\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 2s 313us/sample - loss: 0.1360 - acc: 0.9771 - val_loss: 1.5942 - val_acc: 0.6720\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 2s 317us/sample - loss: 0.1246 - acc: 0.9791 - val_loss: 1.6301 - val_acc: 0.6617\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 2s 316us/sample - loss: 0.1215 - acc: 0.9790 - val_loss: 1.7444 - val_acc: 0.6542\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 2s 312us/sample - loss: 0.1007 - acc: 0.9840 - val_loss: 1.7614 - val_acc: 0.6473\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 2s 318us/sample - loss: 0.1061 - acc: 0.9819 - val_loss: 1.6605 - val_acc: 0.6772\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 2s 317us/sample - loss: 0.0993 - acc: 0.9840 - val_loss: 1.9188 - val_acc: 0.6369\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 2s 320us/sample - loss: 0.0956 - acc: 0.9843 - val_loss: 1.7968 - val_acc: 0.6502\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 2s 318us/sample - loss: 0.0931 - acc: 0.9850 - val_loss: 1.8038 - val_acc: 0.6651\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 2s 323us/sample - loss: 0.0956 - acc: 0.9842 - val_loss: 1.9757 - val_acc: 0.6404\n",
      "4345/4345 [==============================] - 1s 192us/sample - loss: 0.5817 - acc: 0.8928\n",
      "Score for fold 2: loss of 0.5816878253729078; acc of 89.27502632141113%\n",
      "Train on 6952 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6952/6952 [==============================] - 2s 344us/sample - loss: 0.1685 - acc: 0.9694 - val_loss: 1.8251 - val_acc: 0.6582\n",
      "Epoch 2/20\n",
      "6952/6952 [==============================] - 2s 318us/sample - loss: 0.1519 - acc: 0.9731 - val_loss: 2.1496 - val_acc: 0.6007\n",
      "Epoch 3/20\n",
      "6952/6952 [==============================] - 2s 316us/sample - loss: 0.1469 - acc: 0.9722 - val_loss: 2.0517 - val_acc: 0.6226\n",
      "Epoch 4/20\n",
      "6952/6952 [==============================] - 2s 317us/sample - loss: 0.1116 - acc: 0.9806 - val_loss: 1.7690 - val_acc: 0.6795\n",
      "Epoch 5/20\n",
      "6952/6952 [==============================] - 2s 319us/sample - loss: 0.1205 - acc: 0.9789 - val_loss: 1.9529 - val_acc: 0.6565\n",
      "Epoch 6/20\n",
      "6952/6952 [==============================] - 2s 317us/sample - loss: 0.1329 - acc: 0.9763 - val_loss: 2.0918 - val_acc: 0.6369\n",
      "Epoch 7/20\n",
      "6952/6952 [==============================] - 2s 319us/sample - loss: 0.1071 - acc: 0.9820 - val_loss: 2.0903 - val_acc: 0.6473\n",
      "Epoch 8/20\n",
      "6952/6952 [==============================] - 2s 315us/sample - loss: 0.1183 - acc: 0.9799 - val_loss: 1.7838 - val_acc: 0.6801\n",
      "Epoch 9/20\n",
      "6952/6952 [==============================] - 2s 314us/sample - loss: 0.1023 - acc: 0.9823 - val_loss: 2.0352 - val_acc: 0.6461\n",
      "Epoch 10/20\n",
      "6952/6952 [==============================] - 2s 313us/sample - loss: 0.1129 - acc: 0.9804 - val_loss: 2.2025 - val_acc: 0.6277\n",
      "Epoch 11/20\n",
      "6952/6952 [==============================] - 2s 311us/sample - loss: 0.0899 - acc: 0.9849 - val_loss: 1.9896 - val_acc: 0.6738\n",
      "Epoch 12/20\n",
      "6952/6952 [==============================] - 2s 325us/sample - loss: 0.1036 - acc: 0.9825 - val_loss: 1.7159 - val_acc: 0.7031\n",
      "Epoch 13/20\n",
      "6952/6952 [==============================] - 2s 313us/sample - loss: 0.1046 - acc: 0.9825 - val_loss: 1.9097 - val_acc: 0.6732\n",
      "Epoch 14/20\n",
      "6952/6952 [==============================] - 2s 315us/sample - loss: 0.1074 - acc: 0.9810 - val_loss: 2.1401 - val_acc: 0.6421\n",
      "Epoch 15/20\n",
      "6952/6952 [==============================] - 2s 314us/sample - loss: 0.0969 - acc: 0.9840 - val_loss: 1.8802 - val_acc: 0.6922\n",
      "Epoch 16/20\n",
      "6952/6952 [==============================] - 2s 319us/sample - loss: 0.0744 - acc: 0.9882 - val_loss: 2.1562 - val_acc: 0.6421\n",
      "Epoch 17/20\n",
      "6952/6952 [==============================] - 2s 315us/sample - loss: 0.0849 - acc: 0.9863 - val_loss: 1.9943 - val_acc: 0.6795\n",
      "Epoch 18/20\n",
      "6952/6952 [==============================] - 2s 313us/sample - loss: 0.0758 - acc: 0.9875 - val_loss: 1.8101 - val_acc: 0.7158\n",
      "Epoch 19/20\n",
      "6952/6952 [==============================] - 2s 313us/sample - loss: 0.0862 - acc: 0.9862 - val_loss: 2.2249 - val_acc: 0.6525\n",
      "Epoch 20/20\n",
      "6952/6952 [==============================] - 2s 319us/sample - loss: 0.0793 - acc: 0.9863 - val_loss: 2.0279 - val_acc: 0.6778\n",
      "4344/4344 [==============================] - 1s 209us/sample - loss: 0.4553 - acc: 0.9286\n",
      "Score for fold 3: loss of 0.45530422550024086; acc of 92.86372065544128%\n",
      "Wall time: 2min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models import *\n",
    "from training.utils import cv_training\n",
    "\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model = None\n",
    "model = prototype_model_for_reid((40, 40, 1), y_masks_train.shape[1])\n",
    "\n",
    "cv_training(model=model, n_splits=3, x_data=[x_masks, x_lbp], y_data=y_lbp, path_to_save_results='models/texture-silhouette/own/combined', batch_size=60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261/2261 [==============================] - 1s 246us/sample - loss: 1.8518 - acc: 0.4299\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.8518066626636922, 0.42989826]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "model = load_model('models/texture-silhouette/own/combined/model_3.h5')\n",
    "model.evaluate([x_masks_test/255, x_lbp_test/255], y_masks_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Market-1501"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from processing import load_image_dataset\n",
    "\n",
    "x_lbp_train, y_lbp_train = load_image_dataset('Datasets/Market-1501/Market-1501-lbp/train_all', (40, 40), True)\n",
    "\n",
    "x_masks_train, y_masks_train = load_image_dataset('Datasets/Market-1501/Market-1501-masks/train_all', (40, 40), True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train rgb shape: (10784, 40, 40, 1) \t x train masks shape: (10784, 40, 40, 1) \t same?: True\n"
     ]
    }
   ],
   "source": [
    "print(\"x train rgb shape: {} \\t x train masks shape: {} \\t same?: {}\".format(x_lbp_train.shape, x_masks_train.shape, x_lbp_train.shape==x_masks_train.shape ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(751, (10784, 751))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_masks_train[0]), y_masks_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training silhouette re-id model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 1s 213us/sample - loss: 6.4166 - acc: 0.0064 - val_loss: 7.5696 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 6.2293 - acc: 0.0054 - val_loss: 11.8494 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 6.1919 - acc: 0.0077 - val_loss: 9.3562 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 6.1211 - acc: 0.0117 - val_loss: 13.5038 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 1s 152us/sample - loss: 5.9993 - acc: 0.0144 - val_loss: 11.9416 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 151us/sample - loss: 5.8347 - acc: 0.0202 - val_loss: 14.4831 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 148us/sample - loss: 5.6074 - acc: 0.0271 - val_loss: 15.9279 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 1s 148us/sample - loss: 5.3340 - acc: 0.0443 - val_loss: 18.0301 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 5.0060 - acc: 0.0661 - val_loss: 19.3717 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 4.6334 - acc: 0.0929 - val_loss: 21.6995 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 4.2219 - acc: 0.1362 - val_loss: 23.5847 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 141us/sample - loss: 3.7814 - acc: 0.1880 - val_loss: 26.1742 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 3.3297 - acc: 0.2471 - val_loss: 27.5952 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 2.8989 - acc: 0.3215 - val_loss: 29.0290 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 2.4360 - acc: 0.4123 - val_loss: 31.7594 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 2.0701 - acc: 0.4790 - val_loss: 38.2247 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 1.6906 - acc: 0.5667 - val_loss: 40.4897 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 1.3918 - acc: 0.6378 - val_loss: 41.8058 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 1.0920 - acc: 0.7027 - val_loss: 46.0147 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 0.8954 - acc: 0.7536 - val_loss: 48.9262 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 190us/sample - loss: 25.3452 - acc: 0.0078\n",
      "Score for fold 1: loss of 25.34515689855159; acc of 0.7788595277816057%\n",
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 5.5808 - acc: 0.2730 - val_loss: 16.5578 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 4.3942 - acc: 0.3257 - val_loss: 18.3226 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 3.6275 - acc: 0.4022 - val_loss: 19.2441 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 2.9717 - acc: 0.4549 - val_loss: 22.8943 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 2.3558 - acc: 0.5392 - val_loss: 24.4665 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 1.8201 - acc: 0.6187 - val_loss: 28.4389 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 141us/sample - loss: 1.3408 - acc: 0.7041 - val_loss: 30.0088 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 0.9576 - acc: 0.7818 - val_loss: 34.9301 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 0.6641 - acc: 0.8414 - val_loss: 36.8043 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 0.4570 - acc: 0.8818 - val_loss: 40.2864 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 151us/sample - loss: 0.3163 - acc: 0.9171 - val_loss: 40.3960 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 150us/sample - loss: 0.2590 - acc: 0.9277 - val_loss: 41.9763 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 0.1617 - acc: 0.9565 - val_loss: 46.2328 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 0.1431 - acc: 0.9590 - val_loss: 45.8055 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 0.1387 - acc: 0.9577 - val_loss: 45.7989 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 0.1148 - acc: 0.9663 - val_loss: 46.4094 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 0.1018 - acc: 0.9685 - val_loss: 49.2604 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 156us/sample - loss: 0.1043 - acc: 0.9690 - val_loss: 49.4872 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 200us/sample - loss: 0.1111 - acc: 0.9654 - val_loss: 44.5977 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 0.0853 - acc: 0.9770 - val_loss: 46.4569 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 182us/sample - loss: 18.6695 - acc: 0.0743\n",
      "Score for fold 2: loss of 18.66946256953254; acc of 7.426981627941132%\n",
      "Train on 5752 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5752/5752 [==============================] - 1s 174us/sample - loss: 3.7457 - acc: 0.4694 - val_loss: 19.4066 - val_acc: 0.0063\n",
      "Epoch 2/20\n",
      "5752/5752 [==============================] - 1s 141us/sample - loss: 2.0788 - acc: 0.5888 - val_loss: 22.8895 - val_acc: 0.0035\n",
      "Epoch 3/20\n",
      "5752/5752 [==============================] - 1s 145us/sample - loss: 1.3031 - acc: 0.7065 - val_loss: 26.3892 - val_acc: 0.0028\n",
      "Epoch 4/20\n",
      "5752/5752 [==============================] - 1s 145us/sample - loss: 0.7748 - acc: 0.8060 - val_loss: 29.0539 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5752/5752 [==============================] - 1s 147us/sample - loss: 0.4535 - acc: 0.8833 - val_loss: 32.7667 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5752/5752 [==============================] - 1s 148us/sample - loss: 0.2589 - acc: 0.9334 - val_loss: 34.8646 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5752/5752 [==============================] - 1s 152us/sample - loss: 0.1774 - acc: 0.9524 - val_loss: 37.4919 - val_acc: 0.0014\n",
      "Epoch 8/20\n",
      "5752/5752 [==============================] - 1s 142us/sample - loss: 0.1465 - acc: 0.9623 - val_loss: 37.9703 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5752/5752 [==============================] - 1s 143us/sample - loss: 0.1146 - acc: 0.9675 - val_loss: 38.5476 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5752/5752 [==============================] - 1s 141us/sample - loss: 0.0957 - acc: 0.9739 - val_loss: 39.6676 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.1020 - acc: 0.9685 - val_loss: 40.0637 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5752/5752 [==============================] - 1s 148us/sample - loss: 0.0961 - acc: 0.9710 - val_loss: 39.1333 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5752/5752 [==============================] - 1s 141us/sample - loss: 0.0772 - acc: 0.9762 - val_loss: 40.5692 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.0930 - acc: 0.9701 - val_loss: 41.2150 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5752/5752 [==============================] - 1s 143us/sample - loss: 0.0890 - acc: 0.9739 - val_loss: 40.5103 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5752/5752 [==============================] - 1s 143us/sample - loss: 0.0660 - acc: 0.9795 - val_loss: 39.4395 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.0825 - acc: 0.9731 - val_loss: 39.5439 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5752/5752 [==============================] - 1s 147us/sample - loss: 0.0764 - acc: 0.9758 - val_loss: 40.6017 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5752/5752 [==============================] - 1s 147us/sample - loss: 0.0588 - acc: 0.9819 - val_loss: 41.5498 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5752/5752 [==============================] - 1s 144us/sample - loss: 0.0675 - acc: 0.9765 - val_loss: 38.2496 - val_acc: 0.0000e+00\n",
      "3594/3594 [==============================] - 1s 180us/sample - loss: 11.0954 - acc: 0.3200\n",
      "Score for fold 3: loss of 11.095381245854568; acc of 31.997773051261902%\n",
      "Wall time: 56.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models import individual_feature_model\n",
    "from training.utils import cv_training\n",
    "\n",
    "model = individual_feature_model((40, 40, 1), y_masks_train.shape[1])\n",
    "cv_training(model=model, n_splits=3, x_data=[x_masks_train/255]   , y_data=y_lbp_train, path_to_save_results='models/texture-silhouette/market-1501/silhouette')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training textures re-id model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 1s 241us/sample - loss: 6.4114 - acc: 0.0066 - val_loss: 7.9651 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 6.2243 - acc: 0.0077 - val_loss: 8.6683 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 6.2005 - acc: 0.0047 - val_loss: 9.7715 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 6.1921 - acc: 0.0083 - val_loss: 10.6870 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 6.1792 - acc: 0.0078 - val_loss: 16.2131 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 6.1760 - acc: 0.0085 - val_loss: 11.3269 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 6.1651 - acc: 0.0083 - val_loss: 13.6053 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 6.1457 - acc: 0.0111 - val_loss: 11.2838 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 6.1034 - acc: 0.0111 - val_loss: 14.5112 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 6.0364 - acc: 0.0122 - val_loss: 13.4735 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 5.9387 - acc: 0.0156 - val_loss: 16.4605 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 5.8327 - acc: 0.0202 - val_loss: 16.1216 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 5.7057 - acc: 0.0240 - val_loss: 16.7444 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 5.5671 - acc: 0.0303 - val_loss: 17.6543 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 5.4051 - acc: 0.0365 - val_loss: 18.4116 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 148us/sample - loss: 5.2312 - acc: 0.0417 - val_loss: 18.5239 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 5.0115 - acc: 0.0523 - val_loss: 21.3267 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 4.8047 - acc: 0.0659 - val_loss: 23.0349 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 148us/sample - loss: 4.5683 - acc: 0.0821 - val_loss: 23.8503 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 4.3104 - acc: 0.1062 - val_loss: 27.5463 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 171us/sample - loss: 11.9940 - acc: 0.0114\n",
      "Score for fold 1: loss of 11.99402023973319; acc of 1.1404728516936302%\n",
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 5.6208 - acc: 0.0737 - val_loss: 16.2235 - val_acc: 6.9541e-04\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 5.2820 - acc: 0.0854 - val_loss: 15.6513 - val_acc: 0.0014\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 4.9499 - acc: 0.0969 - val_loss: 20.2289 - val_acc: 6.9541e-04\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 4.6584 - acc: 0.1167 - val_loss: 21.9845 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 4.3344 - acc: 0.1516 - val_loss: 22.0539 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 4.0155 - acc: 0.1845 - val_loss: 23.5810 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 3.7377 - acc: 0.2146 - val_loss: 25.4913 - val_acc: 6.9541e-04\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 3.4067 - acc: 0.2589 - val_loss: 25.0756 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 3.1278 - acc: 0.3022 - val_loss: 28.1096 - val_acc: 6.9541e-04\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 155us/sample - loss: 2.8348 - acc: 0.3455 - val_loss: 28.7899 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 2.5131 - acc: 0.4006 - val_loss: 31.5767 - val_acc: 6.9541e-04\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 2.2536 - acc: 0.4507 - val_loss: 34.9836 - val_acc: 6.9541e-04\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 2.0061 - acc: 0.5022 - val_loss: 36.9002 - val_acc: 6.9541e-04\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 1.7406 - acc: 0.5622 - val_loss: 38.7987 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 1s 141us/sample - loss: 1.5091 - acc: 0.6112 - val_loss: 42.8349 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 1.2938 - acc: 0.6632 - val_loss: 41.9478 - val_acc: 6.9541e-04\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 1.0894 - acc: 0.7173 - val_loss: 45.8692 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 0.9359 - acc: 0.7505 - val_loss: 48.6177 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 0.7686 - acc: 0.7929 - val_loss: 47.2908 - val_acc: 6.9541e-04\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 0.6205 - acc: 0.8329 - val_loss: 54.0559 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 170us/sample - loss: 22.4975 - acc: 0.0275\n",
      "Score for fold 2: loss of 22.497547161330434; acc of 2.7538247406482697%\n",
      "Train on 5752 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5752/5752 [==============================] - 1s 144us/sample - loss: 4.6747 - acc: 0.3334 - val_loss: 21.1608 - val_acc: 0.0014\n",
      "Epoch 2/20\n",
      "5752/5752 [==============================] - 1s 143us/sample - loss: 3.7448 - acc: 0.3929 - val_loss: 19.1455 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 3.2154 - acc: 0.4444 - val_loss: 23.1194 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 2.7853 - acc: 0.4894 - val_loss: 22.9091 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5752/5752 [==============================] - 1s 151us/sample - loss: 2.3954 - acc: 0.5271 - val_loss: 25.7266 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5752/5752 [==============================] - 1s 144us/sample - loss: 2.0308 - acc: 0.5735 - val_loss: 28.6100 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5752/5752 [==============================] - 1s 145us/sample - loss: 1.7169 - acc: 0.6285 - val_loss: 27.2861 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5752/5752 [==============================] - 1s 143us/sample - loss: 1.4299 - acc: 0.6742 - val_loss: 29.6589 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5752/5752 [==============================] - 1s 147us/sample - loss: 1.1474 - acc: 0.7328 - val_loss: 32.5657 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.9599 - acc: 0.7738 - val_loss: 33.9602 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5752/5752 [==============================] - 1s 144us/sample - loss: 0.7418 - acc: 0.8133 - val_loss: 34.8375 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5752/5752 [==============================] - 1s 144us/sample - loss: 0.5440 - acc: 0.8677 - val_loss: 36.5148 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.4169 - acc: 0.8971 - val_loss: 40.2590 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5752/5752 [==============================] - 1s 148us/sample - loss: 0.3160 - acc: 0.9245 - val_loss: 43.2536 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5752/5752 [==============================] - 1s 143us/sample - loss: 0.2880 - acc: 0.9338 - val_loss: 42.8533 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5752/5752 [==============================] - 1s 145us/sample - loss: 0.2532 - acc: 0.9412 - val_loss: 43.9392 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5752/5752 [==============================] - 1s 143us/sample - loss: 0.1880 - acc: 0.9581 - val_loss: 46.5297 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.2067 - acc: 0.9525 - val_loss: 45.5601 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5752/5752 [==============================] - 1s 143us/sample - loss: 0.2210 - acc: 0.9529 - val_loss: 41.9900 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.0293 - acc: 0.9981 - val_loss: 50.2272 - val_acc: 0.0000e+00\n",
      "3594/3594 [==============================] - 1s 198us/sample - loss: 16.2157 - acc: 0.1508\n",
      "Score for fold 3: loss of 16.21567855308503; acc of 15.080690383911133%\n",
      "Wall time: 57.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models import individual_feature_model\n",
    "from training.utils import cv_training\n",
    "model = None\n",
    "model = individual_feature_model((40, 40, 1), y_masks_train.shape[1])\n",
    "cv_training(model=model, n_splits=3, x_data=[x_lbp_train/255], y_data=y_lbp_train, path_to_save_results='models/texture-silhouette/market-1501/texture')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Double features re-id model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 5s 837us/sample - loss: 6.5573 - acc: 0.0037 - val_loss: 6.9236 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 4s 610us/sample - loss: 6.4257 - acc: 0.0061 - val_loss: 7.2695 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 4s 620us/sample - loss: 6.3331 - acc: 0.0064 - val_loss: 7.6356 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 4s 614us/sample - loss: 6.2688 - acc: 0.0082 - val_loss: 8.0204 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 4s 628us/sample - loss: 6.2278 - acc: 0.0082 - val_loss: 8.4160 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 4s 629us/sample - loss: 6.2022 - acc: 0.0082 - val_loss: 8.8198 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 4s 626us/sample - loss: 6.1871 - acc: 0.0082 - val_loss: 9.2298 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 4s 658us/sample - loss: 6.1801 - acc: 0.0082 - val_loss: 9.6441 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 4s 624us/sample - loss: 6.1786 - acc: 0.0082 - val_loss: 10.0570 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 4s 612us/sample - loss: 6.1799 - acc: 0.0082 - val_loss: 10.2059 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 4s 643us/sample - loss: 6.1808 - acc: 0.0082 - val_loss: 10.8029 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 4s 633us/sample - loss: 6.1805 - acc: 0.0082 - val_loss: 10.4217 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 3s 607us/sample - loss: 6.1745 - acc: 0.0082 - val_loss: 9.6114 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 3s 597us/sample - loss: 6.1651 - acc: 0.0082 - val_loss: 11.4495 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 3s 602us/sample - loss: 6.1533 - acc: 0.0082 - val_loss: 10.4155 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 3s 605us/sample - loss: 6.1331 - acc: 0.0082 - val_loss: 10.9612 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 4s 623us/sample - loss: 6.1078 - acc: 0.0087 - val_loss: 10.9446 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 4s 612us/sample - loss: 6.0776 - acc: 0.0099 - val_loss: 11.7462 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 3s 603us/sample - loss: 6.0472 - acc: 0.0096 - val_loss: 11.5719 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 3s 600us/sample - loss: 6.0133 - acc: 0.0108 - val_loss: 12.0513 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 224us/sample - loss: 7.4028 - acc: 0.0056\n",
      "Score for fold 1: loss of 7.402790567772113; acc of 0.5563282407820225%\n",
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 3s 604us/sample - loss: 6.1420 - acc: 0.0071 - val_loss: 11.0762 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 4s 614us/sample - loss: 6.0921 - acc: 0.0129 - val_loss: 11.2730 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 3s 602us/sample - loss: 6.0484 - acc: 0.0117 - val_loss: 11.8209 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 4s 624us/sample - loss: 5.9986 - acc: 0.0130 - val_loss: 11.7510 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 3s 605us/sample - loss: 5.9497 - acc: 0.0141 - val_loss: 11.8704 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 3s 607us/sample - loss: 5.9066 - acc: 0.0156 - val_loss: 11.9296 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 4s 633us/sample - loss: 5.8710 - acc: 0.0158 - val_loss: 12.1977 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 4s 618us/sample - loss: 5.8225 - acc: 0.0170 - val_loss: 12.4741 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 4s 627us/sample - loss: 5.7863 - acc: 0.0200 - val_loss: 12.9421 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 4s 679us/sample - loss: 5.7513 - acc: 0.0207 - val_loss: 13.4188 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 4s 624us/sample - loss: 5.7090 - acc: 0.0230 - val_loss: 13.6160 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 4s 666us/sample - loss: 5.6779 - acc: 0.0240 - val_loss: 13.1692 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 4s 663us/sample - loss: 5.6408 - acc: 0.0247 - val_loss: 13.6187 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 4s 662us/sample - loss: 5.6094 - acc: 0.0235 - val_loss: 13.6568 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 4s 761us/sample - loss: 5.5771 - acc: 0.0252 - val_loss: 13.8415 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 4s 683us/sample - loss: 5.5506 - acc: 0.0263 - val_loss: 13.8035 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 4s 648us/sample - loss: 5.5140 - acc: 0.0261 - val_loss: 13.7861 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 4s 635us/sample - loss: 5.4824 - acc: 0.0278 - val_loss: 14.0793 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 4s 645us/sample - loss: 5.4474 - acc: 0.0264 - val_loss: 14.1357 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 4s 666us/sample - loss: 5.4214 - acc: 0.0270 - val_loss: 14.3765 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 264us/sample - loss: 8.0546 - acc: 0.0067\n",
      "Score for fold 2: loss of 8.054608416391513; acc of 0.6675938609987497%\n",
      "Train on 5752 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5752/5752 [==============================] - 4s 628us/sample - loss: 5.9879 - acc: 0.0165 - val_loss: 13.8815 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5752/5752 [==============================] - 4s 626us/sample - loss: 5.8975 - acc: 0.0186 - val_loss: 14.0690 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5752/5752 [==============================] - 4s 657us/sample - loss: 5.8448 - acc: 0.0200 - val_loss: 14.2152 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5752/5752 [==============================] - 4s 685us/sample - loss: 5.7745 - acc: 0.0217 - val_loss: 14.0742 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5752/5752 [==============================] - 4s 722us/sample - loss: 5.7048 - acc: 0.0236 - val_loss: 14.2486 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5752/5752 [==============================] - 4s 645us/sample - loss: 5.6323 - acc: 0.0259 - val_loss: 14.6478 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5752/5752 [==============================] - 4s 649us/sample - loss: 5.5786 - acc: 0.0282 - val_loss: 14.5056 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5752/5752 [==============================] - 4s 723us/sample - loss: 5.5105 - acc: 0.0285 - val_loss: 14.6964 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5752/5752 [==============================] - 4s 699us/sample - loss: 5.4633 - acc: 0.0297 - val_loss: 14.7289 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5752/5752 [==============================] - 4s 619us/sample - loss: 5.4164 - acc: 0.0329 - val_loss: 14.9801 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5752/5752 [==============================] - 4s 649us/sample - loss: 5.3647 - acc: 0.0339 - val_loss: 14.9495 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5752/5752 [==============================] - 3s 605us/sample - loss: 5.3192 - acc: 0.0337 - val_loss: 14.8817 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5752/5752 [==============================] - 4s 614us/sample - loss: 5.2773 - acc: 0.0358 - val_loss: 14.5845 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5752/5752 [==============================] - 4s 613us/sample - loss: 5.2430 - acc: 0.0362 - val_loss: 14.8154 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5752/5752 [==============================] - 4s 662us/sample - loss: 5.2135 - acc: 0.0372 - val_loss: 15.0425 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5752/5752 [==============================] - 4s 661us/sample - loss: 5.1684 - acc: 0.0382 - val_loss: 14.8224 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5752/5752 [==============================] - 4s 656us/sample - loss: 5.1355 - acc: 0.0400 - val_loss: 14.9832 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5752/5752 [==============================] - 4s 611us/sample - loss: 5.1022 - acc: 0.0396 - val_loss: 14.8045 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5752/5752 [==============================] - 4s 635us/sample - loss: 5.0627 - acc: 0.0424 - val_loss: 15.2740 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5752/5752 [==============================] - 4s 631us/sample - loss: 5.0347 - acc: 0.0416 - val_loss: 15.1529 - val_acc: 0.0000e+00\n",
      "3594/3594 [==============================] - 1s 247us/sample - loss: 7.8860 - acc: 0.0139\n",
      "Score for fold 3: loss of 7.885999240142874; acc of 1.3912076130509377%\n",
      "Wall time: 3min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models import prototype_model_for_reid\n",
    "from training.utils import cv_training\n",
    "model=None\n",
    "model = prototype_model_for_reid((40, 40, 1), y_masks_train.shape[1])\n",
    "cv_training(model=model, n_splits=3, x_data=[x_masks_train/255, x_lbp_train/255]   , y_data=y_lbp_train, path_to_save_results='models/texture-silhouette/market-1501/combined', batch_size=20, epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}