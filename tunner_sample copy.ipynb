{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TF tunner samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from processing import load_image_dataset\n",
    "x_masked_train, y_masked_train = load_image_dataset('Datasets/espe/masked/train', (40, 40), False)\n",
    "x_masked_test, y_masked_test = load_image_dataset('Datasets/espe/masked/test', (40, 40), False)\n",
    "x_masked_validation, y_masked_validation = load_image_dataset('Datasets/espe/masked/validation', (40, 40), False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from processing import slice_labels\n",
    "x_masks_train, y_masks_train = load_image_dataset('Datasets/espe/masks/train', (40, 40), False)\n",
    "x_masks_test, y_masks_test = load_image_dataset('Datasets/espe/masks/test', (40, 40), False)\n",
    "x_masks_validation, y_masks_validation = load_image_dataset('Datasets/espe/masks/validation', (40, 40), False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((10507, 40, 40, 3), (10507, 40, 40, 3))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_masked_train.shape, x_masks_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_masks, y_masks = np.concatenate((x_masks_train, x_masks_validation), axis=0), np.concatenate((y_masks_train, y_masks_validation), axis=0)\n",
    "x_data, y_data = np.concatenate((x_masked_train, x_masked_validation), axis=0), np.concatenate((y_masked_train, y_masked_validation), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13034, 40, 40, 3)\n",
      "(13034, 40, 40, 3)\n",
      "(13034, 7)\n",
      "(13034, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(True, True)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_masks.shape == x_data.shape, y_masks.shape == y_data.shape\n",
    "print(x_masks.shape)\n",
    "print(x_data.shape)\n",
    "print(y_masks.shape)\n",
    "print(y_data.shape)\n",
    "x_masks.shape == x_data.shape, y_masks.shape == y_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training model with masked images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 3s 383us/sample - loss: 9.6023 - acc: 0.7733 - val_loss: 16.0579 - val_acc: 0.7301\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 1s 164us/sample - loss: 0.2253 - acc: 0.9686 - val_loss: 13.6130 - val_acc: 0.7670\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 1s 161us/sample - loss: 0.0766 - acc: 0.9876 - val_loss: 11.5444 - val_acc: 0.7796\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 1s 206us/sample - loss: 0.0462 - acc: 0.9925 - val_loss: 10.9765 - val_acc: 0.8078\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 2s 262us/sample - loss: 0.0118 - acc: 0.9973 - val_loss: 10.1251 - val_acc: 0.8055\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 1s 171us/sample - loss: 0.0021 - acc: 0.9991 - val_loss: 10.5649 - val_acc: 0.7601\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 1s 153us/sample - loss: 0.0141 - acc: 0.9963 - val_loss: 9.4871 - val_acc: 0.8096\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 1s 150us/sample - loss: 7.8974e-04 - acc: 0.9997 - val_loss: 9.7333 - val_acc: 0.8285\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 1s 147us/sample - loss: 1.2643e-04 - acc: 1.0000 - val_loss: 9.0582 - val_acc: 0.8096\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 1s 171us/sample - loss: 5.3693e-05 - acc: 1.0000 - val_loss: 9.2177 - val_acc: 0.8303\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 1s 149us/sample - loss: 5.1256e-05 - acc: 1.0000 - val_loss: 9.2575 - val_acc: 0.8136\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 1s 149us/sample - loss: 2.4082e-05 - acc: 1.0000 - val_loss: 9.2839 - val_acc: 0.8193\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 1s 155us/sample - loss: 1.7810e-05 - acc: 1.0000 - val_loss: 9.3141 - val_acc: 0.8222\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 1s 157us/sample - loss: 1.5321e-05 - acc: 1.0000 - val_loss: 9.3355 - val_acc: 0.8222\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 1s 149us/sample - loss: 1.3754e-05 - acc: 1.0000 - val_loss: 9.3570 - val_acc: 0.8234\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 1s 147us/sample - loss: 1.2498e-05 - acc: 1.0000 - val_loss: 9.3752 - val_acc: 0.8234\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 1s 159us/sample - loss: 1.1513e-05 - acc: 1.0000 - val_loss: 9.3926 - val_acc: 0.8234\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 1s 149us/sample - loss: 1.0659e-05 - acc: 1.0000 - val_loss: 9.4067 - val_acc: 0.8245\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 1s 151us/sample - loss: 9.9755e-06 - acc: 1.0000 - val_loss: 9.4201 - val_acc: 0.8239\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 1s 149us/sample - loss: 9.3763e-06 - acc: 1.0000 - val_loss: 9.4336 - val_acc: 0.8251\n",
      "4345/4345 [==============================] - 1s 171us/sample - loss: 1.9875 - acc: 0.9579\n",
      "Score for fold 1: loss of 1.9874796521777438; acc of 95.78826427459717%\n",
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 1s 151us/sample - loss: 0.3016 - acc: 0.9694 - val_loss: 19.5426 - val_acc: 0.6507\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 1s 148us/sample - loss: 35.9475 - acc: 0.7995 - val_loss: 411.6002 - val_acc: 0.5650\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 1s 148us/sample - loss: 56.1839 - acc: 0.8842 - val_loss: 178.6057 - val_acc: 0.7727\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 1s 148us/sample - loss: 2.4669 - acc: 0.9797 - val_loss: 192.3739 - val_acc: 0.7537\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 1s 154us/sample - loss: 0.4955 - acc: 0.9928 - val_loss: 194.3186 - val_acc: 0.8096\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 1s 157us/sample - loss: 0.1528 - acc: 0.9953 - val_loss: 190.1459 - val_acc: 0.7911\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 1s 159us/sample - loss: 0.0822 - acc: 0.9967 - val_loss: 195.9811 - val_acc: 0.8072\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 1s 151us/sample - loss: 0.0220 - acc: 0.9983 - val_loss: 194.6349 - val_acc: 0.8193\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 1s 150us/sample - loss: 0.0271 - acc: 0.9984 - val_loss: 189.7505 - val_acc: 0.7785\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 1s 147us/sample - loss: 0.0223 - acc: 0.9986 - val_loss: 193.4074 - val_acc: 0.8084\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 1s 149us/sample - loss: 0.0029 - acc: 0.9999 - val_loss: 194.6593 - val_acc: 0.8090\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 1s 154us/sample - loss: 9.0360e-04 - acc: 0.9999 - val_loss: 194.4993 - val_acc: 0.8003\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 1s 169us/sample - loss: 9.4035e-04 - acc: 0.9999 - val_loss: 191.6538 - val_acc: 0.8096\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 1s 153us/sample - loss: 2.7306e-06 - acc: 1.0000 - val_loss: 191.4289 - val_acc: 0.8072\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 1s 155us/sample - loss: 3.1179e-06 - acc: 1.0000 - val_loss: 191.4514 - val_acc: 0.8078\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 1s 149us/sample - loss: 2.6259e-06 - acc: 1.0000 - val_loss: 191.4724 - val_acc: 0.8078\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 1s 147us/sample - loss: 2.2456e-06 - acc: 1.0000 - val_loss: 191.4886 - val_acc: 0.8078\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 1s 147us/sample - loss: 1.9848e-06 - acc: 1.0000 - val_loss: 191.5025 - val_acc: 0.8084\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 1s 148us/sample - loss: 1.7840e-06 - acc: 1.0000 - val_loss: 191.5156 - val_acc: 0.8084\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 1s 149us/sample - loss: 1.6245e-06 - acc: 1.0000 - val_loss: 191.5319 - val_acc: 0.8090\n",
      "4345/4345 [==============================] - 1s 168us/sample - loss: 36.1977 - acc: 0.9602\n",
      "Score for fold 2: loss of 36.197705648873274; acc of 96.0184097290039%\n",
      "Train on 6952 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6952/6952 [==============================] - 1s 150us/sample - loss: 0.2846 - acc: 0.9963 - val_loss: 175.3149 - val_acc: 0.7722\n",
      "Epoch 2/20\n",
      "6952/6952 [==============================] - 1s 148us/sample - loss: 0.5449 - acc: 0.9950 - val_loss: 204.6889 - val_acc: 0.8003\n",
      "Epoch 3/20\n",
      "6952/6952 [==============================] - 1s 154us/sample - loss: 0.2049 - acc: 0.9957 - val_loss: 179.3796 - val_acc: 0.7641\n",
      "Epoch 4/20\n",
      "6952/6952 [==============================] - 1s 158us/sample - loss: 0.0507 - acc: 0.9981 - val_loss: 183.3923 - val_acc: 0.8165\n",
      "Epoch 5/20\n",
      "6952/6952 [==============================] - 1s 148us/sample - loss: 0.0164 - acc: 0.9984 - val_loss: 182.1885 - val_acc: 0.7773\n",
      "Epoch 6/20\n",
      "6952/6952 [==============================] - 1s 148us/sample - loss: 0.0229 - acc: 0.9984 - val_loss: 185.1239 - val_acc: 0.7946\n",
      "Epoch 7/20\n",
      "6952/6952 [==============================] - 1s 148us/sample - loss: 0.0141 - acc: 0.9988 - val_loss: 177.0950 - val_acc: 0.7739\n",
      "Epoch 8/20\n",
      "6952/6952 [==============================] - 1s 149us/sample - loss: 0.0075 - acc: 0.9996 - val_loss: 179.9828 - val_acc: 0.7848\n",
      "Epoch 9/20\n",
      "6952/6952 [==============================] - 1s 149us/sample - loss: 0.0715 - acc: 0.9991 - val_loss: 181.9336 - val_acc: 0.8026\n",
      "Epoch 10/20\n",
      "6952/6952 [==============================] - 1s 147us/sample - loss: 0.0054 - acc: 0.9991 - val_loss: 183.5909 - val_acc: 0.7773\n",
      "Epoch 11/20\n",
      "6952/6952 [==============================] - 1s 147us/sample - loss: 0.0046 - acc: 0.9996 - val_loss: 183.1532 - val_acc: 0.7831\n",
      "Epoch 12/20\n",
      "6952/6952 [==============================] - 1s 147us/sample - loss: 0.0022 - acc: 0.9999 - val_loss: 183.1485 - val_acc: 0.7819\n",
      "Epoch 13/20\n",
      "6952/6952 [==============================] - 1s 150us/sample - loss: 1.0026e-06 - acc: 1.0000 - val_loss: 183.1588 - val_acc: 0.7819\n",
      "Epoch 14/20\n",
      "6952/6952 [==============================] - 1s 153us/sample - loss: 1.0346e-06 - acc: 1.0000 - val_loss: 183.1603 - val_acc: 0.7819\n",
      "Epoch 15/20\n",
      "6952/6952 [==============================] - 1s 161us/sample - loss: 7.5772e-07 - acc: 1.0000 - val_loss: 183.1615 - val_acc: 0.7819\n",
      "Epoch 16/20\n",
      "6952/6952 [==============================] - 1s 150us/sample - loss: 6.2743e-07 - acc: 1.0000 - val_loss: 183.1646 - val_acc: 0.7814\n",
      "Epoch 17/20\n",
      "6952/6952 [==============================] - 1s 149us/sample - loss: 5.5181e-07 - acc: 1.0000 - val_loss: 183.1673 - val_acc: 0.7814\n",
      "Epoch 18/20\n",
      "6952/6952 [==============================] - 1s 151us/sample - loss: 4.8295e-07 - acc: 1.0000 - val_loss: 183.1702 - val_acc: 0.7814\n",
      "Epoch 19/20\n",
      "6952/6952 [==============================] - 1s 153us/sample - loss: 4.4047e-07 - acc: 1.0000 - val_loss: 183.1734 - val_acc: 0.7814\n",
      "Epoch 20/20\n",
      "6952/6952 [==============================] - 1s 151us/sample - loss: 4.0606e-07 - acc: 1.0000 - val_loss: 183.1759 - val_acc: 0.7814\n",
      "4344/4344 [==============================] - 1s 154us/sample - loss: 37.3624 - acc: 0.9570\n",
      "Score for fold 3: loss of 37.36235327196419; acc of 95.69520950317383%\n",
      "Wall time: 1min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models2 import image_classification\n",
    "from training.utils import cv_training\n",
    "\n",
    "model = None\n",
    "\n",
    "model = image_classification((40, 40, 3))\n",
    "\n",
    "cv_training(model = model , x_data=[x_data], y_data=y_data, path_to_save_results='models/own/experiments/Pamela/color/experiment_0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training model with masks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 2s 328us/sample - loss: 4.9898 - acc: 0.1936 - val_loss: 1.9587 - val_acc: 0.1916\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 1s 140us/sample - loss: 1.5492 - acc: 0.4194 - val_loss: 2.2700 - val_acc: 0.2301\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 1.2093 - acc: 0.5586 - val_loss: 2.2383 - val_acc: 0.2629\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 1s 136us/sample - loss: 0.9859 - acc: 0.6454 - val_loss: 2.2659 - val_acc: 0.2831\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.7989 - acc: 0.7149 - val_loss: 2.4311 - val_acc: 0.2992\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 1s 124us/sample - loss: 0.6812 - acc: 0.7587 - val_loss: 2.4995 - val_acc: 0.3032\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.5761 - acc: 0.8012 - val_loss: 2.6531 - val_acc: 0.3257\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 1s 138us/sample - loss: 0.5155 - acc: 0.8148 - val_loss: 2.5686 - val_acc: 0.3251\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 1s 135us/sample - loss: 0.4120 - acc: 0.8537 - val_loss: 3.1133 - val_acc: 0.3280\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 1s 124us/sample - loss: 0.4001 - acc: 0.8560 - val_loss: 3.1461 - val_acc: 0.3234\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.3409 - acc: 0.8764 - val_loss: 3.2784 - val_acc: 0.3331\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 1s 133us/sample - loss: 0.2542 - acc: 0.9138 - val_loss: 3.6846 - val_acc: 0.3291\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.2901 - acc: 0.8950 - val_loss: 3.4614 - val_acc: 0.3516\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 1s 127us/sample - loss: 0.2151 - acc: 0.9271 - val_loss: 3.8773 - val_acc: 0.3475\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.1871 - acc: 0.9314 - val_loss: 3.9850 - val_acc: 0.3406\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 1s 124us/sample - loss: 0.1570 - acc: 0.9465 - val_loss: 4.5853 - val_acc: 0.3297\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 1s 122us/sample - loss: 0.1145 - acc: 0.9580 - val_loss: 4.4329 - val_acc: 0.3412\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 1s 124us/sample - loss: 0.1028 - acc: 0.9663 - val_loss: 4.8464 - val_acc: 0.3234\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 1s 128us/sample - loss: 0.1272 - acc: 0.9558 - val_loss: 4.8689 - val_acc: 0.3412\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 1s 136us/sample - loss: 0.1071 - acc: 0.9609 - val_loss: 4.9853 - val_acc: 0.3280\n",
      "4345/4345 [==============================] - 1s 146us/sample - loss: 1.7979 - acc: 0.6819\n",
      "Score for fold 1: loss of 1.7978554683309842; acc of 68.19332838058472%\n",
      "Train on 6951 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6951/6951 [==============================] - 1s 122us/sample - loss: 0.5084 - acc: 0.8403 - val_loss: 2.9884 - val_acc: 0.3458\n",
      "Epoch 2/20\n",
      "6951/6951 [==============================] - 1s 123us/sample - loss: 0.3140 - acc: 0.8914 - val_loss: 3.2090 - val_acc: 0.3446\n",
      "Epoch 3/20\n",
      "6951/6951 [==============================] - 1s 121us/sample - loss: 0.2063 - acc: 0.9320 - val_loss: 3.6496 - val_acc: 0.3734\n",
      "Epoch 4/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.2062 - acc: 0.9266 - val_loss: 3.9086 - val_acc: 0.3654\n",
      "Epoch 5/20\n",
      "6951/6951 [==============================] - 1s 128us/sample - loss: 0.1577 - acc: 0.9443 - val_loss: 4.4119 - val_acc: 0.3320\n",
      "Epoch 6/20\n",
      "6951/6951 [==============================] - 1s 121us/sample - loss: 0.1104 - acc: 0.9614 - val_loss: 4.9113 - val_acc: 0.3694\n",
      "Epoch 7/20\n",
      "6951/6951 [==============================] - 1s 123us/sample - loss: 0.0868 - acc: 0.9714 - val_loss: 4.7550 - val_acc: 0.3705\n",
      "Epoch 8/20\n",
      "6951/6951 [==============================] - 1s 124us/sample - loss: 0.0618 - acc: 0.9806 - val_loss: 5.9443 - val_acc: 0.3625\n",
      "Epoch 9/20\n",
      "6951/6951 [==============================] - 1s 128us/sample - loss: 0.0615 - acc: 0.9780 - val_loss: 5.4578 - val_acc: 0.3303\n",
      "Epoch 10/20\n",
      "6951/6951 [==============================] - 1s 124us/sample - loss: 0.0945 - acc: 0.9675 - val_loss: 5.7024 - val_acc: 0.3728\n",
      "Epoch 11/20\n",
      "6951/6951 [==============================] - 1s 131us/sample - loss: 0.1155 - acc: 0.9591 - val_loss: 5.2095 - val_acc: 0.3533\n",
      "Epoch 12/20\n",
      "6951/6951 [==============================] - 1s 135us/sample - loss: 0.1495 - acc: 0.9502 - val_loss: 5.3723 - val_acc: 0.3475\n",
      "Epoch 13/20\n",
      "6951/6951 [==============================] - 1s 122us/sample - loss: 0.0798 - acc: 0.9741 - val_loss: 5.6138 - val_acc: 0.3481\n",
      "Epoch 14/20\n",
      "6951/6951 [==============================] - 1s 122us/sample - loss: 0.0498 - acc: 0.9830 - val_loss: 6.4899 - val_acc: 0.3498\n",
      "Epoch 15/20\n",
      "6951/6951 [==============================] - 1s 122us/sample - loss: 0.1116 - acc: 0.9610 - val_loss: 5.8141 - val_acc: 0.3567\n",
      "Epoch 16/20\n",
      "6951/6951 [==============================] - 1s 125us/sample - loss: 0.0855 - acc: 0.9708 - val_loss: 5.6774 - val_acc: 0.3625\n",
      "Epoch 17/20\n",
      "6951/6951 [==============================] - 1s 120us/sample - loss: 0.0531 - acc: 0.9816 - val_loss: 5.8332 - val_acc: 0.3763\n",
      "Epoch 18/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.0458 - acc: 0.9836 - val_loss: 5.8458 - val_acc: 0.3717\n",
      "Epoch 19/20\n",
      "6951/6951 [==============================] - 1s 126us/sample - loss: 0.0397 - acc: 0.9875 - val_loss: 6.1550 - val_acc: 0.3544\n",
      "Epoch 20/20\n",
      "6951/6951 [==============================] - 1s 121us/sample - loss: 0.0460 - acc: 0.9830 - val_loss: 6.4852 - val_acc: 0.3631\n",
      "4345/4345 [==============================] - 1s 155us/sample - loss: 1.5358 - acc: 0.7938\n",
      "Score for fold 2: loss of 1.5358375489794285; acc of 79.37859892845154%\n",
      "Train on 6952 samples, validate on 1738 samples\n",
      "Epoch 1/20\n",
      "6952/6952 [==============================] - 1s 145us/sample - loss: 0.3131 - acc: 0.9054 - val_loss: 3.9054 - val_acc: 0.3959\n",
      "Epoch 2/20\n",
      "6952/6952 [==============================] - 1s 121us/sample - loss: 0.2340 - acc: 0.9173 - val_loss: 4.3040 - val_acc: 0.3613\n",
      "Epoch 3/20\n",
      "6952/6952 [==============================] - 1s 164us/sample - loss: 0.1207 - acc: 0.9594 - val_loss: 4.3729 - val_acc: 0.3993\n",
      "Epoch 4/20\n",
      "6952/6952 [==============================] - 1s 122us/sample - loss: 0.0625 - acc: 0.9777 - val_loss: 5.3076 - val_acc: 0.3895\n",
      "Epoch 5/20\n",
      "6952/6952 [==============================] - 1s 121us/sample - loss: 0.0527 - acc: 0.9814 - val_loss: 5.1033 - val_acc: 0.4143\n",
      "Epoch 6/20\n",
      "6952/6952 [==============================] - 1s 129us/sample - loss: 0.0458 - acc: 0.9843 - val_loss: 6.1088 - val_acc: 0.3970\n",
      "Epoch 7/20\n",
      "6952/6952 [==============================] - 1s 141us/sample - loss: 0.0397 - acc: 0.9855 - val_loss: 5.6451 - val_acc: 0.4016\n",
      "Epoch 8/20\n",
      "6952/6952 [==============================] - 1s 123us/sample - loss: 0.0596 - acc: 0.9789 - val_loss: 5.4510 - val_acc: 0.4154\n",
      "Epoch 9/20\n",
      "6952/6952 [==============================] - 1s 126us/sample - loss: 0.0848 - acc: 0.9718 - val_loss: 5.3045 - val_acc: 0.3982\n",
      "Epoch 10/20\n",
      "6952/6952 [==============================] - 1s 123us/sample - loss: 0.0556 - acc: 0.9814 - val_loss: 5.9712 - val_acc: 0.4033\n",
      "Epoch 11/20\n",
      "6952/6952 [==============================] - 1s 125us/sample - loss: 0.0283 - acc: 0.9907 - val_loss: 6.4729 - val_acc: 0.4033\n",
      "Epoch 12/20\n",
      "6952/6952 [==============================] - 1s 124us/sample - loss: 0.0179 - acc: 0.9950 - val_loss: 6.6969 - val_acc: 0.3953\n",
      "Epoch 13/20\n",
      "6952/6952 [==============================] - 1s 123us/sample - loss: 0.0144 - acc: 0.9955 - val_loss: 6.6652 - val_acc: 0.4033\n",
      "Epoch 14/20\n",
      "6952/6952 [==============================] - 1s 125us/sample - loss: 0.0092 - acc: 0.9971 - val_loss: 6.7542 - val_acc: 0.4217\n",
      "Epoch 15/20\n",
      "6952/6952 [==============================] - 1s 122us/sample - loss: 0.0123 - acc: 0.9958 - val_loss: 6.6482 - val_acc: 0.4114\n",
      "Epoch 16/20\n",
      "6952/6952 [==============================] - 1s 118us/sample - loss: 0.0129 - acc: 0.9954 - val_loss: 7.1377 - val_acc: 0.3987\n",
      "Epoch 17/20\n",
      "6952/6952 [==============================] - 1s 123us/sample - loss: 0.0156 - acc: 0.9940 - val_loss: 6.9787 - val_acc: 0.4160\n",
      "Epoch 18/20\n",
      "6952/6952 [==============================] - 1s 122us/sample - loss: 0.0319 - acc: 0.9894 - val_loss: 7.0404 - val_acc: 0.3918\n",
      "Epoch 19/20\n",
      "6952/6952 [==============================] - 1s 126us/sample - loss: 0.0406 - acc: 0.9845 - val_loss: 7.8631 - val_acc: 0.3625\n",
      "Epoch 20/20\n",
      "6952/6952 [==============================] - 1s 120us/sample - loss: 0.1034 - acc: 0.9678 - val_loss: 6.0216 - val_acc: 0.3803\n",
      "4344/4344 [==============================] - 1s 154us/sample - loss: 1.4676 - acc: 0.8147\n",
      "Score for fold 3: loss of 1.4676434040933797; acc of 81.46869540214539%\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models2 import silhouette_cnn_model\n",
    "from training.utils import cv_training\n",
    "\n",
    "model = None\n",
    "\n",
    "model = silhouette_cnn_model((40, 40, 3))\n",
    "\n",
    "cv_training(model = model , x_data=[x_masks], y_data=y_masks, path_to_save_results='models/own/experiments/Pamela/silueta_2/experiment_0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training model with masks - color"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models2 import multi_input_model\n",
    "from training.utils import cv_training\n",
    "\n",
    "model = multi_input_model()\n",
    "\n",
    "cv_training(model = model , x_data=[x_data, x_masks], y_data=y_masks, path_to_save_results='models/own/experiments/Pamela/color_silueta/experiment_0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Market-1501"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from processing import load_image_dataset\n",
    "x_masked_train, y_masked_train = load_image_dataset('Datasets/Market-1501/Market-1501-masked/train_all', (40, 40), False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "x_masks_train, y_masks_train = load_image_dataset('Datasets/Market-1501/Market-1501-masks/train_all', (40, 40), False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Color"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 2s 426us/sample - loss: 11.9249 - acc: 0.0061 - val_loss: 8.7119 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 5.9814 - acc: 0.0123 - val_loss: 12.5750 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 5.5287 - acc: 0.0266 - val_loss: 14.0519 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 142us/sample - loss: 5.2333 - acc: 0.0379 - val_loss: 15.2652 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 1s 148us/sample - loss: 4.9766 - acc: 0.0501 - val_loss: 16.4667 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 149us/sample - loss: 4.7101 - acc: 0.0727 - val_loss: 16.4605 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 4.5202 - acc: 0.0807 - val_loss: 18.8279 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 4.2288 - acc: 0.1052 - val_loss: 19.8995 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 4.0220 - acc: 0.1269 - val_loss: 20.0897 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 3.8769 - acc: 0.1452 - val_loss: 19.9697 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 3.7914 - acc: 0.1515 - val_loss: 21.4269 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 3.5347 - acc: 0.1746 - val_loss: 23.1051 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 1s 148us/sample - loss: 3.3817 - acc: 0.1977 - val_loss: 22.8329 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 3.1861 - acc: 0.2254 - val_loss: 23.3591 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 1s 148us/sample - loss: 3.1576 - acc: 0.2257 - val_loss: 25.2993 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 2.8945 - acc: 0.2808 - val_loss: 26.6034 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 2.7366 - acc: 0.2980 - val_loss: 28.3774 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 143us/sample - loss: 2.7071 - acc: 0.3100 - val_loss: 24.0513 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 152us/sample - loss: 2.7157 - acc: 0.3013 - val_loss: 26.1858 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 2.5027 - acc: 0.3434 - val_loss: 30.3014 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 201us/sample - loss: 10.3512 - acc: 0.1118\n",
      "Score for fold 1: loss of 10.351201776072113; acc of 11.18219718337059%\n",
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 1s 155us/sample - loss: 3.6681 - acc: 0.2254 - val_loss: 19.6507 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 3.2285 - acc: 0.2546 - val_loss: 22.2038 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 2.8924 - acc: 0.2989 - val_loss: 25.4734 - val_acc: 6.9541e-04\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 2.6084 - acc: 0.3490 - val_loss: 26.5450 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 2.3722 - acc: 0.3918 - val_loss: 31.7644 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 2.4121 - acc: 0.3827 - val_loss: 30.1842 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 2.1923 - acc: 0.4158 - val_loss: 30.9090 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 1s 148us/sample - loss: 2.0191 - acc: 0.4533 - val_loss: 33.6771 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 2.0527 - acc: 0.4391 - val_loss: 33.2058 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 1.8202 - acc: 0.4954 - val_loss: 34.6987 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 1.7532 - acc: 0.5100 - val_loss: 35.2086 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 148us/sample - loss: 1.7988 - acc: 0.5140 - val_loss: 38.2949 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 1s 149us/sample - loss: 1.5276 - acc: 0.5676 - val_loss: 41.3341 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 1.4202 - acc: 0.5862 - val_loss: 43.4936 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 1.4284 - acc: 0.5922 - val_loss: 39.7904 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 1.6253 - acc: 0.5437 - val_loss: 35.6646 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 147us/sample - loss: 1.5006 - acc: 0.5762 - val_loss: 42.5665 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 146us/sample - loss: 1.3453 - acc: 0.6128 - val_loss: 41.9586 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 144us/sample - loss: 1.2353 - acc: 0.6359 - val_loss: 42.6089 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 145us/sample - loss: 1.3147 - acc: 0.6274 - val_loss: 44.0899 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 181us/sample - loss: 13.6516 - acc: 0.1608\n",
      "Score for fold 2: loss of 13.65155414904938; acc of 16.077886521816254%\n",
      "Train on 5752 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5752/5752 [==============================] - 1s 189us/sample - loss: 3.1782 - acc: 0.3559 - val_loss: 27.6183 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5752/5752 [==============================] - 1s 149us/sample - loss: 2.2838 - acc: 0.4513 - val_loss: 28.7241 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5752/5752 [==============================] - 1s 147us/sample - loss: 1.9234 - acc: 0.5150 - val_loss: 32.8925 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5752/5752 [==============================] - 1s 147us/sample - loss: 1.6408 - acc: 0.5751 - val_loss: 34.8626 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 1.5447 - acc: 0.5774 - val_loss: 35.2721 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5752/5752 [==============================] - 1s 147us/sample - loss: 1.4665 - acc: 0.5890 - val_loss: 40.1536 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 1.2723 - acc: 0.6370 - val_loss: 43.7716 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5752/5752 [==============================] - 1s 144us/sample - loss: 1.1189 - acc: 0.6770 - val_loss: 42.5406 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5752/5752 [==============================] - 1s 150us/sample - loss: 1.0833 - acc: 0.6893 - val_loss: 47.8234 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5752/5752 [==============================] - 1s 154us/sample - loss: 1.0650 - acc: 0.6921 - val_loss: 47.4108 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5752/5752 [==============================] - 1s 149us/sample - loss: 1.0034 - acc: 0.7093 - val_loss: 48.2396 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.9484 - acc: 0.7229 - val_loss: 45.8866 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5752/5752 [==============================] - 1s 147us/sample - loss: 0.8800 - acc: 0.7429 - val_loss: 48.9318 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5752/5752 [==============================] - 1s 148us/sample - loss: 0.9168 - acc: 0.7364 - val_loss: 50.8630 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5752/5752 [==============================] - 1s 149us/sample - loss: 1.1014 - acc: 0.6932 - val_loss: 51.5950 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.9512 - acc: 0.7197 - val_loss: 53.2750 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5752/5752 [==============================] - 1s 146us/sample - loss: 0.8470 - acc: 0.7563 - val_loss: 51.6516 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5752/5752 [==============================] - 1s 149us/sample - loss: 0.8070 - acc: 0.7717 - val_loss: 56.5898 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5752/5752 [==============================] - 1s 143us/sample - loss: 0.7993 - acc: 0.7665 - val_loss: 53.2664 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5752/5752 [==============================] - 1s 144us/sample - loss: 0.9699 - acc: 0.7359 - val_loss: 50.6541 - val_acc: 0.0000e+00\n",
      "3594/3594 [==============================] - 1s 195us/sample - loss: 13.1269 - acc: 0.2565\n",
      "Score for fold 3: loss of 13.12686698013501; acc of 25.653868913650513%\n",
      "Wall time: 59.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models2 import image_classification\n",
    "from training.utils import cv_training\n",
    "\n",
    "model = None\n",
    "\n",
    "model = image_classification((40, 40, 3))\n",
    "\n",
    "cv_training(model = model , x_data=[x_masked_train], y_data=y_masked_train, path_to_save_results='models/own/experiments/Pamela/market-1501/color/experiment_0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Silhouette"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 1s 195us/sample - loss: 6.9257 - acc: 0.0040 - val_loss: 8.3868 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 1s 128us/sample - loss: 6.2141 - acc: 0.0054 - val_loss: 9.3712 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 1s 126us/sample - loss: 6.1732 - acc: 0.0066 - val_loss: 10.1977 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 127us/sample - loss: 6.1078 - acc: 0.0094 - val_loss: 10.3173 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 1s 126us/sample - loss: 6.0041 - acc: 0.0111 - val_loss: 10.2161 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 126us/sample - loss: 5.8866 - acc: 0.0129 - val_loss: 12.8169 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 5.7454 - acc: 0.0177 - val_loss: 12.3958 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 1s 126us/sample - loss: 5.5651 - acc: 0.0256 - val_loss: 13.5998 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 5.3887 - acc: 0.0327 - val_loss: 13.8177 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 122us/sample - loss: 5.1703 - acc: 0.0409 - val_loss: 14.5894 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 122us/sample - loss: 4.9245 - acc: 0.0555 - val_loss: 14.7715 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 126us/sample - loss: 4.6899 - acc: 0.0741 - val_loss: 15.7385 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 4.4083 - acc: 0.1022 - val_loss: 17.1966 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 1s 126us/sample - loss: 4.1243 - acc: 0.1240 - val_loss: 19.4889 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 1s 125us/sample - loss: 3.8908 - acc: 0.1542 - val_loss: 19.0867 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 122us/sample - loss: 3.6438 - acc: 0.1888 - val_loss: 19.9280 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 3.3394 - acc: 0.2222 - val_loss: 22.8163 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 3.1161 - acc: 0.2641 - val_loss: 24.5475 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 2.8895 - acc: 0.3008 - val_loss: 24.8494 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 2.6767 - acc: 0.3424 - val_loss: 27.0370 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 150us/sample - loss: 15.7637 - acc: 0.0033\n",
      "Score for fold 1: loss of 15.763701133038305; acc of 0.33379693049937487%\n",
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 1s 125us/sample - loss: 5.9946 - acc: 0.0633 - val_loss: 11.3925 - val_acc: 6.9541e-04\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 1s 126us/sample - loss: 5.2296 - acc: 0.1130 - val_loss: 14.2854 - val_acc: 6.9541e-04\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 1s 128us/sample - loss: 4.7465 - acc: 0.1681 - val_loss: 15.7705 - val_acc: 0.0014\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 4.3191 - acc: 0.2015 - val_loss: 18.2414 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 1s 123us/sample - loss: 3.9303 - acc: 0.2363 - val_loss: 19.2500 - val_acc: 6.9541e-04\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 3.5730 - acc: 0.2631 - val_loss: 20.8053 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 123us/sample - loss: 3.3084 - acc: 0.2890 - val_loss: 23.5518 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 1s 122us/sample - loss: 3.0484 - acc: 0.3264 - val_loss: 24.1584 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 1s 122us/sample - loss: 2.7373 - acc: 0.3589 - val_loss: 27.9379 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 123us/sample - loss: 2.5279 - acc: 0.3975 - val_loss: 28.8387 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 125us/sample - loss: 2.3453 - acc: 0.4199 - val_loss: 30.9505 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 126us/sample - loss: 2.1678 - acc: 0.4533 - val_loss: 34.0662 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 1.9306 - acc: 0.4973 - val_loss: 33.3569 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 1s 121us/sample - loss: 1.8336 - acc: 0.5251 - val_loss: 36.1121 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 1.7465 - acc: 0.5371 - val_loss: 36.3261 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 124us/sample - loss: 1.5335 - acc: 0.5837 - val_loss: 38.4998 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 123us/sample - loss: 1.5493 - acc: 0.5846 - val_loss: 42.3913 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 127us/sample - loss: 1.4239 - acc: 0.6147 - val_loss: 41.9664 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 125us/sample - loss: 1.3001 - acc: 0.6385 - val_loss: 42.3453 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 127us/sample - loss: 1.1336 - acc: 0.6780 - val_loss: 46.5448 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 176us/sample - loss: 19.1066 - acc: 0.0231\n",
      "Score for fold 2: loss of 19.106556437443295; acc of 2.3087622597813606%\n",
      "Train on 5752 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5752/5752 [==============================] - 1s 127us/sample - loss: 5.0113 - acc: 0.1787 - val_loss: 17.0040 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5752/5752 [==============================] - 1s 122us/sample - loss: 3.6664 - acc: 0.2836 - val_loss: 22.4033 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5752/5752 [==============================] - 1s 127us/sample - loss: 2.9676 - acc: 0.3893 - val_loss: 25.1952 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5752/5752 [==============================] - 1s 123us/sample - loss: 2.4506 - acc: 0.4508 - val_loss: 28.1634 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5752/5752 [==============================] - 1s 125us/sample - loss: 2.0949 - acc: 0.5087 - val_loss: 31.0616 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5752/5752 [==============================] - 1s 122us/sample - loss: 1.7836 - acc: 0.5607 - val_loss: 35.9629 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5752/5752 [==============================] - 1s 122us/sample - loss: 1.6027 - acc: 0.5930 - val_loss: 36.8284 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5752/5752 [==============================] - 1s 124us/sample - loss: 1.4239 - acc: 0.6205 - val_loss: 39.3059 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5752/5752 [==============================] - 1s 129us/sample - loss: 1.3918 - acc: 0.6196 - val_loss: 43.2231 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5752/5752 [==============================] - 1s 125us/sample - loss: 1.2986 - acc: 0.6455 - val_loss: 43.4966 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5752/5752 [==============================] - 1s 126us/sample - loss: 1.1564 - acc: 0.6723 - val_loss: 44.2647 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5752/5752 [==============================] - 1s 128us/sample - loss: 1.1793 - acc: 0.6679 - val_loss: 48.2940 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5752/5752 [==============================] - 1s 131us/sample - loss: 1.1327 - acc: 0.6820 - val_loss: 47.2996 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5752/5752 [==============================] - 1s 128us/sample - loss: 0.9387 - acc: 0.7291 - val_loss: 51.6710 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5752/5752 [==============================] - 1s 123us/sample - loss: 1.0170 - acc: 0.7131 - val_loss: 48.9559 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5752/5752 [==============================] - 1s 127us/sample - loss: 1.0257 - acc: 0.7057 - val_loss: 51.2831 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5752/5752 [==============================] - 1s 125us/sample - loss: 0.8471 - acc: 0.7523 - val_loss: 51.8381 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5752/5752 [==============================] - 1s 127us/sample - loss: 0.7360 - acc: 0.7776 - val_loss: 55.4889 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5752/5752 [==============================] - 1s 125us/sample - loss: 0.6943 - acc: 0.7949 - val_loss: 57.1534 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5752/5752 [==============================] - 1s 124us/sample - loss: 0.6784 - acc: 0.8067 - val_loss: 57.7700 - val_acc: 0.0000e+00\n",
      "3594/3594 [==============================] - 1s 183us/sample - loss: 18.0679 - acc: 0.0826\n",
      "Score for fold 3: loss of 18.067876296767807; acc of 8.26377272605896%\n",
      "Wall time: 48.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models2 import silhouette_cnn_model\n",
    "from training.utils import cv_training\n",
    "\n",
    "model = None\n",
    "\n",
    "model = silhouette_cnn_model((40, 40, 3))\n",
    "\n",
    "cv_training(model = model , x_data=[x_masks_train], y_data=y_masks_train, path_to_save_results='models/own/experiments/Pamela/market-1501/silhouette/experiment_0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# color - silhouette"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 2s 353us/sample - loss: 8.7012 - acc: 0.0104 - val_loss: 9.1534 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 1s 259us/sample - loss: 5.6441 - acc: 0.0325 - val_loss: 13.6755 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 1s 257us/sample - loss: 4.9816 - acc: 0.0513 - val_loss: 16.0997 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 257us/sample - loss: 4.4877 - acc: 0.0779 - val_loss: 16.9851 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 2s 261us/sample - loss: 4.0342 - acc: 0.1228 - val_loss: 18.3570 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 258us/sample - loss: 3.7892 - acc: 0.1555 - val_loss: 20.2586 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 257us/sample - loss: 3.3524 - acc: 0.2059 - val_loss: 19.8585 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 2s 267us/sample - loss: 3.0986 - acc: 0.2445 - val_loss: 21.7532 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 2s 265us/sample - loss: 2.7756 - acc: 0.3019 - val_loss: 24.6673 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 256us/sample - loss: 2.6597 - acc: 0.3205 - val_loss: 23.9277 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 255us/sample - loss: 2.3547 - acc: 0.3839 - val_loss: 25.7926 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 260us/sample - loss: 2.0693 - acc: 0.4458 - val_loss: 26.2189 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 1s 255us/sample - loss: 2.0923 - acc: 0.4411 - val_loss: 26.8079 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 1s 255us/sample - loss: 1.8578 - acc: 0.4857 - val_loss: 25.6455 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 1s 257us/sample - loss: 1.6051 - acc: 0.5451 - val_loss: 26.1905 - val_acc: 6.9541e-04\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 260us/sample - loss: 1.4971 - acc: 0.5724 - val_loss: 32.2408 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 260us/sample - loss: 1.3396 - acc: 0.6049 - val_loss: 30.9899 - val_acc: 6.9541e-04\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 260us/sample - loss: 1.3267 - acc: 0.6115 - val_loss: 33.6991 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 258us/sample - loss: 1.0703 - acc: 0.6792 - val_loss: 34.8751 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 258us/sample - loss: 0.9840 - acc: 0.7006 - val_loss: 33.7306 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 226us/sample - loss: 11.9894 - acc: 0.1744\n",
      "Score for fold 1: loss of 11.989367439153297; acc of 17.44088977575302%\n",
      "Train on 5751 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5751/5751 [==============================] - 1s 260us/sample - loss: 3.0499 - acc: 0.3954 - val_loss: 19.3875 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5751/5751 [==============================] - 2s 264us/sample - loss: 2.1947 - acc: 0.4869 - val_loss: 23.1662 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5751/5751 [==============================] - 2s 262us/sample - loss: 1.6667 - acc: 0.5820 - val_loss: 28.9694 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5751/5751 [==============================] - 1s 259us/sample - loss: 1.4779 - acc: 0.6098 - val_loss: 29.9080 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5751/5751 [==============================] - 1s 257us/sample - loss: 1.3435 - acc: 0.6251 - val_loss: 31.2238 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5751/5751 [==============================] - 1s 258us/sample - loss: 1.2395 - acc: 0.6496 - val_loss: 33.2765 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5751/5751 [==============================] - 1s 257us/sample - loss: 1.5301 - acc: 0.5903 - val_loss: 28.4287 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5751/5751 [==============================] - 1s 256us/sample - loss: 1.1554 - acc: 0.6696 - val_loss: 34.9864 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5751/5751 [==============================] - 1s 260us/sample - loss: 0.8305 - acc: 0.7557 - val_loss: 37.0489 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5751/5751 [==============================] - 1s 258us/sample - loss: 0.8989 - acc: 0.7404 - val_loss: 38.8435 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5751/5751 [==============================] - 1s 258us/sample - loss: 0.7135 - acc: 0.7807 - val_loss: 38.4134 - val_acc: 6.9541e-04\n",
      "Epoch 12/20\n",
      "5751/5751 [==============================] - 1s 258us/sample - loss: 1.1759 - acc: 0.6835 - val_loss: 30.2945 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5751/5751 [==============================] - 2s 262us/sample - loss: 0.8224 - acc: 0.7651 - val_loss: 41.0182 - val_acc: 6.9541e-04\n",
      "Epoch 14/20\n",
      "5751/5751 [==============================] - 2s 267us/sample - loss: 0.6604 - acc: 0.7993 - val_loss: 43.0362 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5751/5751 [==============================] - 2s 265us/sample - loss: 0.6280 - acc: 0.8115 - val_loss: 40.9813 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5751/5751 [==============================] - 1s 256us/sample - loss: 0.7086 - acc: 0.8016 - val_loss: 38.8863 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5751/5751 [==============================] - 1s 254us/sample - loss: 0.6814 - acc: 0.8025 - val_loss: 38.4414 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5751/5751 [==============================] - 1s 257us/sample - loss: 0.5362 - acc: 0.8421 - val_loss: 41.9601 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5751/5751 [==============================] - 1s 258us/sample - loss: 0.6453 - acc: 0.8091 - val_loss: 41.7227 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5751/5751 [==============================] - 1s 258us/sample - loss: 0.6515 - acc: 0.8122 - val_loss: 38.6867 - val_acc: 0.0000e+00\n",
      "3595/3595 [==============================] - 1s 236us/sample - loss: 11.3522 - acc: 0.2737\n",
      "Score for fold 2: loss of 11.352224928812126; acc of 27.371349930763245%\n",
      "Train on 5752 samples, validate on 1438 samples\n",
      "Epoch 1/20\n",
      "5752/5752 [==============================] - 1s 260us/sample - loss: 2.3387 - acc: 0.4998 - val_loss: 23.8601 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5752/5752 [==============================] - 1s 258us/sample - loss: 1.4131 - acc: 0.6349 - val_loss: 27.4312 - val_acc: 0.0021\n",
      "Epoch 3/20\n",
      "5752/5752 [==============================] - 2s 261us/sample - loss: 0.8910 - acc: 0.7552 - val_loss: 35.6482 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5752/5752 [==============================] - 1s 258us/sample - loss: 0.7443 - acc: 0.7823 - val_loss: 38.8677 - val_acc: 0.0028\n",
      "Epoch 5/20\n",
      "5752/5752 [==============================] - 2s 261us/sample - loss: 0.6439 - acc: 0.8136 - val_loss: 38.2205 - val_acc: 0.0014\n",
      "Epoch 6/20\n",
      "5752/5752 [==============================] - 1s 259us/sample - loss: 0.5208 - acc: 0.8416 - val_loss: 43.9170 - val_acc: 6.9541e-04\n",
      "Epoch 7/20\n",
      "5752/5752 [==============================] - 1s 256us/sample - loss: 0.6132 - acc: 0.8230 - val_loss: 40.7402 - val_acc: 6.9541e-04\n",
      "Epoch 8/20\n",
      "5752/5752 [==============================] - 1s 256us/sample - loss: 0.5717 - acc: 0.8321 - val_loss: 42.6993 - val_acc: 0.0021\n",
      "Epoch 9/20\n",
      "5752/5752 [==============================] - 1s 259us/sample - loss: 0.5148 - acc: 0.8468 - val_loss: 42.2413 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5752/5752 [==============================] - 1s 258us/sample - loss: 0.7044 - acc: 0.8037 - val_loss: 41.6763 - val_acc: 0.0014\n",
      "Epoch 11/20\n",
      "5752/5752 [==============================] - 1s 260us/sample - loss: 0.5190 - acc: 0.8486 - val_loss: 38.7518 - val_acc: 0.0014\n",
      "Epoch 12/20\n",
      "5752/5752 [==============================] - 1s 260us/sample - loss: 0.6572 - acc: 0.8155 - val_loss: 42.6796 - val_acc: 0.0028\n",
      "Epoch 13/20\n",
      "5752/5752 [==============================] - 2s 261us/sample - loss: 0.7697 - acc: 0.7858 - val_loss: 39.7756 - val_acc: 6.9541e-04\n",
      "Epoch 14/20\n",
      "5752/5752 [==============================] - 1s 260us/sample - loss: 0.7774 - acc: 0.7808 - val_loss: 38.3127 - val_acc: 0.0021\n",
      "Epoch 15/20\n",
      "5752/5752 [==============================] - 2s 261us/sample - loss: 0.5003 - acc: 0.8555 - val_loss: 46.5755 - val_acc: 0.0014\n",
      "Epoch 16/20\n",
      "5752/5752 [==============================] - 1s 259us/sample - loss: 0.5266 - acc: 0.8536 - val_loss: 44.2972 - val_acc: 6.9541e-04\n",
      "Epoch 17/20\n",
      "5752/5752 [==============================] - 1s 258us/sample - loss: 0.4861 - acc: 0.8635 - val_loss: 43.1922 - val_acc: 0.0021\n",
      "Epoch 18/20\n",
      "5752/5752 [==============================] - 1s 259us/sample - loss: 0.4040 - acc: 0.8778 - val_loss: 44.7355 - val_acc: 0.0021\n",
      "Epoch 19/20\n",
      "5752/5752 [==============================] - 1s 260us/sample - loss: 0.4205 - acc: 0.8797 - val_loss: 46.8538 - val_acc: 6.9541e-04\n",
      "Epoch 20/20\n",
      "5752/5752 [==============================] - 1s 261us/sample - loss: 0.3801 - acc: 0.8953 - val_loss: 48.2611 - val_acc: 6.9541e-04\n",
      "3594/3594 [==============================] - 1s 244us/sample - loss: 11.1452 - acc: 0.4218\n",
      "Score for fold 3: loss of 11.145179031554632; acc of 42.18141436576843%\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from utils.Models2 import multi_input_model\n",
    "from training.utils import cv_training\n",
    "\n",
    "model = None\n",
    "\n",
    "model = multi_input_model()\n",
    "\n",
    "cv_training(model = model , x_data=[x_masked_train, x_masks_train], y_data=y_masks_train, path_to_save_results='models/own/experiments/Pamela/market-1501/combined/experiment_0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9429e3d8733c1ac76f5c3b0c6cdd2706acd1fd7b4f8c91f27a242412c8600fc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}